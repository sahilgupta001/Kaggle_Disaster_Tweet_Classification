{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kaggle_Disaster_Huggingface_BERT",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pEmR2pnDNmp",
        "colab_type": "code",
        "outputId": "47da0009-b702-4274-e720-574c277b2e36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        }
      },
      "source": [
        "!pip install transformers\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from transformers import DistilBertTokenizer, RobertaTokenizer"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.11.0)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.91)\n",
            "Requirement already satisfied: tokenizers==0.7.0 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.15.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZkw08J5D4Zs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.read_csv(\"/content/drive/My Drive/Kaggle_disaster/train.csv\")\n",
        "test = pd.read_csv(\"/content/drive/My Drive/Kaggle_disaster/test.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSUBPbliEURL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "roberta = 'distilbert-base-uncased'\n",
        "tokenizer = DistilBertTokenizer.from_pretrained(roberta, do_lower_case = True, add_special_tokens = True, max_length = 128, pad_to_max_length = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IINh_Vs7TXp5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize(sentences, tokenizer):\n",
        "  input_ids, input_masks, input_segments = [], [], []\n",
        "  for sentence in sentences:\n",
        "    inputs = tokenizer.encode_plus(sentence, add_special_tokens = True, max_length = 128, pad_to_max_length = True, return_attention_mask = True, return_token_type_ids = True)\n",
        "    input_ids.append(inputs['input_ids'])\n",
        "    input_masks.append(inputs['attention_mask'])\n",
        "    input_segments.append(inputs['token_type_ids'])\n",
        "  return np.asarray(input_ids, dtype = \"int32\"), np.asarray(input_masks, dtype = \"int32\"), np.asarray(input_segments, dtype = \"int32\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BV8L-I2xV4xG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_ids, input_masks, input_segments = tokenize(train.text.values, tokenizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f96ks2pZWNa5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import TFDistilBertForSequenceClassification, DistilBertConfig, TFDistilBertModel\n",
        "\n",
        "distil_bert = 'distilbert-base-uncased'\n",
        "\n",
        "config = DistilBertConfig(dropout=0.2, attention_dropout=0.2)\n",
        "config.output_hidden_states = False\n",
        "transformer_model = TFDistilBertModel.from_pretrained(distil_bert, config = config)\n",
        "\n",
        "input_ids_in = tf.keras.layers.Input(shape=(128,), name='input_token', dtype=tf.int32)\n",
        "input_masks_in = tf.keras.layers.Input(shape=(128,), name='masked_token', dtype=tf.int32) \n",
        "embedding_layer = transformer_model(input_ids_in, attention_mask=input_masks_in)[0]\n",
        "X = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(50, return_sequences=True, dropout=0.1, recurrent_dropout=0.1))(embedding_layer)\n",
        "X = tf.keras.layers.GlobalMaxPool1D()(X)\n",
        "X = tf.keras.layers.Dense(50, activation='relu')(X)\n",
        "X = tf.keras.layers.Dropout(0.2)(X)\n",
        "X = tf.keras.layers.Dense(1, activation='sigmoid')(X)\n",
        "model = tf.keras.Model(inputs=[input_ids_in, input_masks_in], outputs = X)\n",
        "model.compile(Adam(lr = 1e-5), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "for layer in model.layers[:3]:\n",
        "  layer.trainable = False\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSpDdpmqZfQy",
        "colab_type": "code",
        "outputId": "6a42c64d-8a3a-45af-93ae-ca63941c7032",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_token (InputLayer)        [(None, 128)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "masked_token (InputLayer)       [(None, 128)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_distil_bert_model_2 (TFDisti ((None, 128, 768),)  66362880    input_token[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice_1 (Te [(None, 768)]        0           tf_distil_bert_model_2[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 768)          3072        tf_op_layer_strided_slice_1[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 256)          196864      batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_59 (Dropout)            (None, 256)          0           dense_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 128)          32896       dropout_59[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_60 (Dropout)            (None, 128)          0           dense_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 1)            129         dropout_60[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 66,595,841\n",
            "Trainable params: 231,425\n",
            "Non-trainable params: 66,364,416\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BT_nPsJG5gH",
        "colab_type": "code",
        "outputId": "87260a98-87d5-4ed3-f929-0fd2541858d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "bert_input = [\n",
        "    input_ids,\n",
        "    input_masks\n",
        "]\n",
        "train_history = model.fit(\n",
        "    bert_input,\n",
        "    train.target.values,\n",
        "    validation_split = 0.2,\n",
        "    batch_size = 16,\n",
        "    epochs = 10\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "164/164 [==============================] - 51s 311ms/step - loss: 0.7983 - accuracy: 0.5103 - val_loss: 0.7266 - val_accuracy: 0.5436\n",
            "Epoch 2/10\n",
            "164/164 [==============================] - 50s 304ms/step - loss: 0.7334 - accuracy: 0.5621 - val_loss: 0.7159 - val_accuracy: 0.5605\n",
            "Epoch 3/10\n",
            "164/164 [==============================] - 50s 304ms/step - loss: 0.6942 - accuracy: 0.5954 - val_loss: 0.7237 - val_accuracy: 0.5544\n",
            "Epoch 4/10\n",
            "164/164 [==============================] - 50s 304ms/step - loss: 0.6946 - accuracy: 0.5927 - val_loss: 0.7192 - val_accuracy: 0.5804\n",
            "Epoch 5/10\n",
            "164/164 [==============================] - 50s 304ms/step - loss: 0.6557 - accuracy: 0.6487 - val_loss: 0.7430 - val_accuracy: 0.5590\n",
            "Epoch 6/10\n",
            "164/164 [==============================] - 50s 303ms/step - loss: 0.6251 - accuracy: 0.6609 - val_loss: 0.7511 - val_accuracy: 0.5605\n",
            "Epoch 7/10\n",
            "164/164 [==============================] - 50s 304ms/step - loss: 0.6002 - accuracy: 0.6874 - val_loss: 0.7756 - val_accuracy: 0.5467\n",
            "Epoch 8/10\n",
            "164/164 [==============================] - 50s 303ms/step - loss: 0.5630 - accuracy: 0.7096 - val_loss: 0.8237 - val_accuracy: 0.5345\n",
            "Epoch 9/10\n",
            "164/164 [==============================] - 50s 303ms/step - loss: 0.5308 - accuracy: 0.7264 - val_loss: 0.8719 - val_accuracy: 0.4977\n",
            "Epoch 10/10\n",
            "164/164 [==============================] - 50s 303ms/step - loss: 0.5025 - accuracy: 0.7533 - val_loss: 0.8907 - val_accuracy: 0.5605\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHcnMDY99XzD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_ids, input_masks, input_segments = tokenize(test.text.values, tokenizer)\n",
        "bert_input = [\n",
        "    input_ids,\n",
        "    input_masks\n",
        "]\n",
        "submission = pd.read_csv(\"/content/sample_submission.csv\")\n",
        "test_pred = model.predict(bert_input)\n",
        "submission['target'] = test_pred.round().astype(int)\n",
        "submission.to_csv('submission.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpd13aY5b1kE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save_weights('/content/drive/My Drive/disaster_model/model_hugging_face1.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UX8pwzwkjqB2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}